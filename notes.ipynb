{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a2a1b8",
   "metadata": {},
   "source": [
    "# DP AD column comma issue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e10f40f1",
   "metadata": {},
   "source": [
    "Ran python code on an extracted AD column from 'GT:AD:DP:GQ:PL' columns associated numeric values column 'num' with row values such as '0/1:10,104:114:30:3516,0,30'. The AD column would be '10,104' in this case. I had an error when splitting and assigning the split AD column into 2 separate columns, but had no issue in splitting the 'num' column based on ':'. Printed number of columns that the split AD column created, and it was 3, with the 3rd column being mostly None, but 23 non-null values present. The solution I implemented was simply to remove the 3rd column, could be artifacts or something more complicated, but could not find significant reason behind keeping it. Also, there were no null values for columns 0 and 1 which are the important Ref and Alt reads columns.\n",
    "\n",
    "Code:\n",
    "if df['AD'].str.contains(',', regex=False).all():\n",
    "    split_AD = df['AD'].str.split(',', expand=True)\n",
    "    print(split_AD)\n",
    "    print(split_AD.iloc[:, 2].notnull().sum())\n",
    "\n",
    "Output:\n",
    "         0    1     2\n",
    "0       10  104  None\n",
    "1       30    5  None\n",
    "2       45   11  None\n",
    "3        8  142  None\n",
    "4       11    5  None\n",
    "...    ...  ...   ...\n",
    "10338   97   73  None\n",
    "10339   75  103  None\n",
    "10340   40   29  None\n",
    "10341   13    7  None\n",
    "10342  158   86  None\n",
    "\n",
    "[10343 rows x 3 columns]\n",
    "23 (number of not null values in col '2')\n",
    "\n",
    "Additional Output showing sum of not null values in col '0' and '1':\n",
    "Used Code: \n",
    "    print(split_AD.iloc[:, 0].notnull().sum())\n",
    "    print(split_AD.iloc[:, 1].notnull().sum())\n",
    "Output:\n",
    "[10343 rows x 3 columns]\n",
    "10343\n",
    "10343"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abfa00",
   "metadata": {},
   "source": [
    "# DP column =/= ALT_READS + REF_READS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63cb760e",
   "metadata": {},
   "source": [
    "For some rows the extracted DP value did not match its respective ALT_READ + REF_READ value:\n",
    "ALT REF DP\n",
    "45 \t11 \t58"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07f179",
   "metadata": {},
   "source": [
    "# Keywords exist in ~1/4 rows of 100M1 file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96a8b9f7",
   "metadata": {},
   "source": [
    "Used Code:\n",
    "    keyword_columns = [keyword + '_exists' for keyword in keywords]\n",
    "    df['ANY_KEYWORD'] = df[keyword_columns].any(axis=1)\n",
    "    print(df['ANY_KEYWORD'].sum())\n",
    "Output:\n",
    "2557 rows have at least one keyword\n",
    "10343 rows Ã— 48 columns\n",
    "\n",
    "Instead of extracting only first occurence, I am extracting all unique keywords found for row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff139f",
   "metadata": {},
   "source": [
    "# Number of keywords distribution (filtered 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4222dbec",
   "metadata": {},
   "source": [
    "After extracting all keywords from each row and compiling them in one column, I wanted to see how many keywords (after filtering out all the rows with no keywords) are there. Simple statistics, found almost always there was just one keywords with a very few instances of 2 or 3 keywords for variant type.\n",
    "\n",
    "Used Code:\n",
    "    # count number of values in each variant type\n",
    "    df['TYPES_COUNT'] = df['TYPES'].str.count(',') + 1\n",
    "    print(df['TYPES_COUNT'].quantile(0.25))\n",
    "    print(df['TYPES_COUNT'].quantile(0.5))\n",
    "    print(df['TYPES_COUNT'].quantile(0.75))\n",
    "    print(df['TYPES_COUNT'].max())\n",
    "Output:\n",
    "    1.0 1.0 1.0\n",
    "    3\n",
    "    \n",
    "Validate that when only one keyword to be extracted (may not necessarily be the first one that shows up in row since we check for each keyword across all rows one at a time) if no commas exist: print((df['VARIANT_TYPE'].str.count(',')).max()) - printed 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af06bf",
   "metadata": {},
   "source": [
    "# Extracting gene- and p. from INFO_19 col"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aab8e9b7",
   "metadata": {},
   "source": [
    "There are a variable number of terms in each row of INFO_19 column. So that means the columns could possibly vary across each row. That is, if we were to find the 'gene-' string was in the x column, generally, it still would not guarantee 'gene-' string was in all entries of this column. Validated this by finding that 'gene-' appeared earliest in the long string of INFO_19 in the 4th column, and then determined if it appeared in all entries of 4th column, it did not, it appeared in ~99.5% of entries.\n",
    "\n",
    "Code (finding distribution statistics of terms in INFO_19):\n",
    "    terms_info19 = df['INFO_19'].str.count('|')\n",
    "    print(terms_info19.min())\n",
    "    print(terms_info19.quantile(0.25))\n",
    "    print(terms_info19.quantile(0.5))\n",
    "    print(terms_info19.quantile(0.75))\n",
    "    print(terms_info19.max())\n",
    "Output:\n",
    "0         670.0\n",
    "1        1353.0\n",
    "          ...  \n",
    "10341    1000.0\n",
    "10342     670.0\n",
    "Name: INFO_19, Length: 10343, dtype: float64\n",
    "\n",
    "min: 17.0\n",
    "q1: 261.0\n",
    "q2: 566.0\n",
    "q3: 1203.5\n",
    "max: 12474.0\n",
    "\n",
    "Code (validating string locations were variable across any column since 'gene-' is not in all entries of column, but is in most - 99.56%):\n",
    "    split_values = df['INFO_19'].str.split('|', expand=True).iloc[:, 4]\n",
    "    print(split_values.str.contains('gene-').all())\n",
    "    print(split_values.str.count('gene-').sum() / len(split_values))\n",
    "Output:\n",
    "False\n",
    "0.9956980836918263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719e301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datascience]",
   "language": "python",
   "name": "conda-env-datascience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
